<p>Entry for December 19th, 2018</p>

<p>Now, it seems we get to the good stuff - things I've never really heard about
  before.  Transfer learning. Take a trained model, replace the last layer with
  something new, and train just that last layer.  This is extremely
  useful.</p>

<p>Lesson 4 of the deep learning tutorial covers this.</p>

<p>Interesting, it seems the example code is importing from Keras libraries
  within TensorFlow, not Keras by itself.</p>

<p>Interesting note from lesson 6 in the Deep Learning track: Becker says,
  models with dense layers for tabular data, models with convolutional layers for
  images. Why?</p>

<p>Batch size = # of rows (tabular data), or # of images (image data)</p>

<p>"...use validation scores as ultimate measure of model quality..." - Dan
Becker, Kaggle Deep Learning Track, Lesson 7</p>

<p>Really important side note: in vim, in whatever the non-insert mode is
  called, I think it is called command mode, but if you have the cursor on
  the curly brace or whatever and you type  '%' it will jump to the closing, and
  oh, wow, ctrl-o goes to the previous location, and ctrl-i or &gt;tab&lt; goes
  to next location.  Those are huge.</p>
